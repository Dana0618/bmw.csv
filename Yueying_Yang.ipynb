{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Pfd-yojA7HD"
      },
      "source": [
        "**Implementation of the Multiple Linear Regression Algorithm**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ql_LMoPBX_h"
      },
      "source": [
        "Model Set-Up\n",
        "\n",
        "> This is to set up the model by importing relevant packages/libraries and reading in the data\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6bCUoF6rPN1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "9b8e4d37-5025-46d8-e914-1a99557b7b09"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import math\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "url = 'https://github.com/Dana0618/bmw.csv.git'\n",
        "car_price = pd.read_csv(url)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ParserError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-39597248026a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://github.com/Dana0618/bmw.csv.git'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mcar_price\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m         \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 28, saw 384\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGKq0AZJBxd3"
      },
      "source": [
        "Data Understanding\n",
        "\n",
        "\n",
        "> Understand the dataset as a whole \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWjVYdSeAT1z"
      },
      "source": [
        "#view the first 5 rows in the dataset\n",
        "car_price.head()\n",
        "#Check for missing values\n",
        "car_price.isna().sum()\n",
        "#describe and find shape of the data\n",
        "car_price.describe()\n",
        "car_price.shape\n",
        "#create a correlation matrix that shows the correlation between all numerical attributes\n",
        "corr=car_price.corr()\n",
        "corr.style.background_gradient(cmap=\"RdYlGn\")\n",
        "#Create graphs for the numerical data\n",
        "sns.pairplot(car_price)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiGgHO7iAUjv"
      },
      "source": [
        "Data Preprocessing\n",
        "> Preprocess and clean the data before using the data in the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSiCqh-6ttO3"
      },
      "source": [
        "#drop the columns that does will not be helpful based on correlation matrix and understanding of attributes\n",
        "car_price['car_age']= 2020-car_price['year']\n",
        "car_price = car_price.drop(['model','year'],axis=1)\n",
        "\n",
        "#Remove Outliers\n",
        "car_price.drop(index=car_price[car_price[\"mileage\"]>160000].index,inplace=True)\n",
        "car_price.drop(index=car_price[car_price[\"mileage\"]<1000].index,inplace=True)\n",
        "car_price.drop(index=car_price[car_price[\"engineSize\"]==0].index,inplace=True)\n",
        "car_price.drop(index=car_price[car_price[\"price\"]<5000].index,inplace=True)\n",
        "car_price.drop(index=car_price[car_price[\"tax\"]<100].index,inplace=True)\n",
        "car_price.drop(index=car_price[car_price[\"mpg\"]>85].index,inplace=True)\n",
        "car_price.drop(index=car_price[car_price[\"engineSize\"]>4].index,inplace=True)\n",
        "\n",
        "#Data Transformation and Creation of New Variables\n",
        "car_price['price']=np.log(car_price['price'])\n",
        "car_price['mileage']=np.log(car_price['mileage'])\n",
        "car_price['mileage_age']= car_price['mileage'] * car_price['car_age']\n",
        "\n",
        "#get a list of all columns that are numerical and categorical\n",
        "num_col = car_price.select_dtypes(exclude=['object']).columns\n",
        "cat_col = car_price.select_dtypes(include=['object']).columns\n",
        "\n",
        "#transform categorical variables into dummy variables\n",
        "dummy_var = pd.get_dummies(car_price[cat_col])\n",
        "dummy_var.shape\n",
        "dummy_var.head()\n",
        "\n",
        "#add new variables to the original dataset\n",
        "car_price = pd.concat([car_price[num_col], dummy_var], axis=1)\n",
        "car_price.head()\n",
        "\n",
        "#Create graphs for the transformed data\n",
        "sns.pairplot(car_price)\n",
        "\n",
        "#create a correlation matrix that shows the correlation between all numerical attributes and the transformed categorical variables\n",
        "corr=car_price.corr()\n",
        "corr.style.background_gradient(cmap=\"RdYlGn\")\n",
        "\n",
        "#Remove variables that have a correlation in the range of -0.45 to 0.45\n",
        "car_price_v1 = car_price.drop(['tax','transmission_Manual','transmission_Automatic','transmission_Semi-Auto','fuelType_Diesel','fuelType_Petrol'],axis=1)\n",
        "\n",
        "#Re-run correlation matrix with the variables\n",
        "corr=car_price_v1.corr()\n",
        "corr.style.background_gradient(cmap=\"RdYlGn\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OZQcUDpCEuM"
      },
      "source": [
        "Algorithm Implementation\n",
        "\n",
        "> Finish setting up the dataset\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQuUqFrHCXjq"
      },
      "source": [
        "#Dataset Set Up\n",
        "Y_df = car_price_v1['price']\n",
        "X_df = car_price_v1.drop(['price'],axis=1)\n",
        "\n",
        "Y = Y_df.values\n",
        "X = X_df.values\n",
        "\n",
        "#Split Dataset into Train and Test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=1)\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoF5I-pj9qat"
      },
      "source": [
        "> Class to implement the key aspects of the Ordinary Least Squares procedure\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HX8DSiZQszan"
      },
      "source": [
        "#create a class for the beta coefficients of the model and make predictions using the Ordinary Least Squares procedure\n",
        "class OrdinaryLeastSquares(object):\n",
        "\n",
        "# Create empty array\n",
        "  def __init__(self):\n",
        "    self.coefficients = []\n",
        "    self.y_predictions = []\n",
        "    self.standard_error = []\n",
        "    self.residuals_y = []\n",
        "    self.t_test = []\n",
        "    self.model_table = []\n",
        "    \n",
        "# Matrix Calculation for the Beta Coefficients - B = (X' * X)^-1 * X' * Y  \n",
        "  def fit(self, X, y):\n",
        "    X = self.add_ones(X)\n",
        "    self.coefficients = np.linalg.inv(X.transpose().dot(X)).dot(X.transpose()).dot(y)\n",
        "\n",
        "#Add a new column of ones to the first column in Matrix X\n",
        "  def add_ones(self, X):\n",
        "    ones = np.ones(shape=X.shape[0]).reshape(-1,1)\n",
        "    return np.concatenate((ones, X), 1)\n",
        "\n",
        "#Using the predicted coefficients, append the predictions into an array\n",
        "  def predict_y(self, X):\n",
        "    for row in X: self.y_predictions.append(self.predict(row))\n",
        "\n",
        "#Create the regression equation to predict the value of price for each row\n",
        "  def predict(self, entry):\n",
        "    b0 = self.coefficients[0]\n",
        "    prediction_betas = self.coefficients[1:]\n",
        "    predictions = b0\n",
        "\n",
        "    for x_i, b_i in zip(entry, prediction_betas): predictions += (b_i * x_i)\n",
        "    return predictions\n",
        "\n",
        "#Standard Error Calculation \n",
        "  def std_error(self, X, Y):\n",
        "    num_obs = len(X)\n",
        "    num_col = len(X[0])\n",
        "    deg_free = num_obs - num_col -1\n",
        "\n",
        "    p_1 = np.asarray(self.residuals(Y, self.y_predictions)/deg_free)\n",
        "    X = self.add_ones(X)\n",
        "\n",
        "    s_e = np.dot(p_1,self.std_e_matrix(X))\n",
        "    self.standard_error = np.diagonal(s_e)\n",
        "  \n",
        "# Matrix Calculation for the Standard Error - X = (X' * X)^-1 \n",
        "  def std_e_matrix(self, X):\n",
        "    matrix_x = np.linalg.inv(X.transpose().dot(X))\n",
        "    return matrix_x\n",
        "\n",
        "#Sum of Y Residuals   \n",
        "  def residuals(self, y, y_predictions):\n",
        "    y_resid = (y-self.y_predictions)**2\n",
        "    y_sum = np.sum(y_resid)\n",
        "    return y_sum\n",
        "\n",
        "#T-Test\n",
        "  def t_test_table (self):\n",
        "    std_error = self.standard_error.transpose()\n",
        "    beta_c = self.coefficients.transpose()\n",
        "\n",
        "    data_t = [beta_c,std_error]\n",
        "\n",
        "    new_df = pd.DataFrame(data=data_t)\n",
        "    self.t_test= new_df.transpose()\n",
        "    self.t_test = self.t_test.rename(columns={0:\"Coefficient\",1:\"Stnd Error\"})\n",
        "    self.t_test[\"t_value\"] = self.t_test[\"Coefficient\"]/self.t_test[\"Stnd Error\"]\n",
        "\n",
        "# Observed and Predictions Table\n",
        "  def final_model_table (self, y_values):\n",
        "    y_predictions = np.array(self.y_predictions)\n",
        "    table = [y_values, y_predictions]\n",
        "    table = pd.DataFrame(data=table)\n",
        "    self.model_table = table.transpose()\n",
        "    self.model_table = self.model_table.rename(columns={0:\"Observed\",1:\"Predicted\"})\n",
        "\n",
        "model = OrdinaryLeastSquares()\n",
        "model.fit(X_train,y_train)\n",
        "model.predict_y(X_train)\n",
        "model.std_error(X_train,y_train)\n",
        "model.t_test_table()\n",
        "\n",
        "y1 = model.y_predictions\n",
        "x1 = model.coefficients\n",
        "model.t_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohsNH_tFX-8f"
      },
      "source": [
        "\n",
        "\n",
        "> Evaluate the Final Model \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FR0ZJ0VvYFLw"
      },
      "source": [
        "#create a class to evaluate the final model\n",
        "class Evaluation(object):\n",
        "\n",
        "#RMSE\n",
        "  def RMSE(self, y, y_predictions):\n",
        "    y_resid = (y_predictions-y)**2\n",
        "    y_sum = np.sum(y_resid)\n",
        "    RMSE = np.sqrt(y_sum/len(y))\n",
        "    return RMSE\n",
        "\n",
        "#R-Sq\n",
        "  def R_Square(self, y, y_predictions):\n",
        "    y_resid = (y-y_predictions)**2\n",
        "    y_sum_a = np.sum(y_resid)\n",
        "\n",
        "    SST= (y- np.mean(y))**2\n",
        "    y_sum_b = np.sum(SST)\n",
        "    R_Sq = 1-(y_sum_a/y_sum_b)\n",
        "    return R_Sq\n",
        "\n",
        "#R-Sq Adj\n",
        "  def R_Sq_Adj(self, X, y, y_predictions):\n",
        "    n = len(y)\n",
        "    m = len(X[0])\n",
        "\n",
        "    R_Sq_Adj = 1 - ((1-self.R_Square(y, y_predictions))*n-1)/(n-m-1)\n",
        "    return R_Sq_Adj\n",
        "\n",
        "#Create a predicted value residual plot\n",
        "  def pred_value_plot (self, y, pred_y):\n",
        "    y_resid = y-pred_y\n",
        "    plt.figure(figsize=(8,8))\n",
        "    plt.title('Residuals')\n",
        "    return plt.plot(pred_y, y_resid, 'o',color='black')\n",
        "\n",
        "#Create a normality histogram\n",
        "  def normality_histogram (self, y, pred_y):\n",
        "    residuals = y-pred_y\n",
        "    plt.figure(figsize=(8,8))\n",
        "    return sns.displot(residuals, kde=True)\n",
        "\n",
        "model_E = Evaluation()\n",
        "model_E.RMSE(y_train,y1)\n",
        "model_E.R_Sq_Adj(X_train, y_train,y1)\n",
        "model_E.R_Square( y_train,y1)\n",
        "model_E.pred_value_plot(y_train,y1)\n",
        "model_E.normality_histogram(y_train,y1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsmUQ0T3YFt-"
      },
      "source": [
        "\n",
        "\n",
        "> Run Regression using the Test Data and Evaluate the Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKANjU5_X_kW"
      },
      "source": [
        "#Run OLS Model\n",
        "model_main = OrdinaryLeastSquares()\n",
        "model_main.fit(X_test,y_test)\n",
        "model_main.predict_y(X_test)\n",
        "model_main.std_error(X_test,y_test)\n",
        "model_main.t_test_table()\n",
        "model_main.final_model_table(y_test)\n",
        "model_main.t_test\n",
        "model_main.model_table\n",
        "\n",
        "y1 = model_main.y_predictions\n",
        "\n",
        "#Run Evaluation\n",
        "model_Evaluation = Evaluation()\n",
        "print(\"The RMSE value is \" + str(model_Evaluation.RMSE(y_test,y1)))\n",
        "print(\"The R2 Adjusted value is \" + str(model_Evaluation.R_Sq_Adj(X_test, y_test,y1)))\n",
        "model_Evaluation.R_Square(y_test,y1)\n",
        "model_Evaluation.pred_value_plot(y_test,y1)\n",
        "model_Evaluation.normality_histogram(y_test,y1)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}